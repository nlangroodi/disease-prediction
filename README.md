# Cancer Detection using Computer Vision
## Final project for INFO 5082

Pertinent Files:
- The `EDA_nuclei_data.ipynb` file includes initial EDA of dataset, changes to dataset, and final modified dataset which is included in the `/data` folder.
- The `train_model.ipynb` files includes data loading, model architecture and training, as well as model evaluation. Final model has been saved in the `/model` folder.
- The `evaluate_model.ipynb` file includes post-evaluation using saved model files.

### Statement of the Project Problem

This project seeks out to determine if a single deep learning model can be created to take in medical images and detect cancer cells among a variety of different types of tissue. The location of the cancerous cells will be annotated in the model’s output. This project requires a labeled medical imaging dataset that will need to be visualized and assessed in an exploratory data analysis (EDA) to determine the nature of the images in which work will be done. Then, different types of neural networks, from modified U-Net to Mask R-CNN, are explored to determine the best model architecture that is suitable for this problem. After this, the model is trained and evaluated by analyzing the model’s learning curves, performance metrics, as well as visualizing resulting images and their predicted masks.

### Objectives of the Study

This study aims to determine if one deep learning model can successfully classify cancerous regions on several different types of tissue. It will also set to establish the best architecture and computer vision concept for creating such a model. 

### Data Collection
	
The dataset for this project has been acquired from a third-party source since experienced labeling is required to acquire the necessary masks where cancerous cells have been identified. The PanNuke dataset has been found from the Tissue Image Analytics Centre that seems sufficient for the study (Gamper, 2019). This dataset includes 7,901 labeled images across three folds. These images were labeled using a semi-supervised method (Gamper et al., 2019). Pathologists labeled a small subset of images that were used to train an ensemble of neural networks. A segmentation model, detection model, and classification model were trained using this dataset. Then, the epistemic model uncertainty was measured to determine which images needed to be re-labeled by a pathologist. These labels were corrected and fed back to the models for reinforcement. This process was performed until the dataset was properly labeled (Gamper et al., 2019).

This dataset holds RGB images that are 256x256 in shape and were collected from nineteen different tissue types. The masks are also 256x256 and have 6 different classification channels: neoplastic cells, inflammatory, connective/soft tissue cells, dead cells, epithelial, and background. This study will group these different channels into two distinct channels for binary segmentation. This is because we only care to determine if a tissue sample is concerning and requires extra attention from doctors. Two different types of groupings were explored in this study. First, neoplastic cells, inflammatory, and dead cells were grouped in the positive class; neoplastic cells are cancerous, inflammatory cells identify could lead to abnormalities (Coussens & Werb, 2001), and dead cells have been found to potentially help cancer cells strengthen (Huzar, 2020). The rest of the channels are grouped as the negative class since they are healthy/background tissue. This grouping is ideal since it can serve as a flag to doctors that a closer look needs to be taken at a certain tissue sample. However, the inflammatory and dead cells classes could potentially add extra variability into this classification and prevent the model from learning cancer features as well as it could. Therefore, a second grouping was also experimented with. The second grouping only identifies the neoplastic cells as the positive class, assuming that cancer is the only target, and all other channels as the negative class. After the masks are converted into a binary format, they are filtered down to only include images that have a labeled mask with both positive and negative classes. This filtering results in the first grouping having 6,097 images while the second grouping has 4,163 images for training and testing. Each grouping still has images from all nineteen different tissue types. The results for each of these datasets were comparable; therefore, the rest of this paper will follow the model that was trained with the first grouping dataset. This new dataset has been saved in the /data folder of this project repository.  
